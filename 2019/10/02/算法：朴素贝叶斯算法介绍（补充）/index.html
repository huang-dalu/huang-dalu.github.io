<!DOCTYPE html>
<html lang="en">
  <head><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">
<meta name="referrer" content="same-origin">
<meta name="referrer" content="no-referrer">

<meta name="description" content="算法：朴素贝叶斯算法介绍（补充）"/><meta name="keywords" content="算法, UX Caff" /><link rel="alternate" href="/atom.xml" title="UX Caff" type="application/atom+xml"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.11.0" />
<link rel="canonical" href="http://example.com/2019/10/02/算法：朴素贝叶斯算法介绍（补充）/"/>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.11.0" />

<script>
  window.config = {"toc":true,"fancybox":false,"pjax":false,"latex":true};
</script>

    <title>算法：朴素贝叶斯算法介绍（补充） - UX Caff</title>
  <meta name="generator" content="Hexo 5.2.0"></head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">UX Caff</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list"><a href="/">
        <li class="mobile-menu-item">Home
          </li>
      </a><a href="/archives/">
        <li class="mobile-menu-item">Archives
          </li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories
          </li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags
          </li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About
          </li>
      </a></ul>
</nav>
<div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="" class="logo">UX Caff</a>
</div>

<nav class="site-navbar"><ul id="menu" class="menu"><li class="menu-item">
          <a class="menu-item-link" href="/">
            Home
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            Archives
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/categories/">
            Categories
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/tags/">
            Tags
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/about/">
            About
            </a>
        </li>
      </ul></nav>
</header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content"><article class="post">
    <header class="post-header">
      <h1 class="post-title">算法：朴素贝叶斯算法介绍（补充）
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-10-02
        </span></div>
    </header>

    <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">Contents</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%8E%9F%E7%90%86"><span class="toc-text">1.贝叶斯原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-sklearn%E4%B8%AD%E7%9A%84%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="toc-text">2.sklearn中的朴素贝叶斯</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E9%AB%98%E6%96%AF%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF-naive-bayes-GaussianNB"><span class="toc-text">2.1 高斯朴素贝叶斯(naive_bayes.GaussianNB)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF-naive-bayes-MultinomialNB"><span class="toc-text">2.2 多项式朴素贝叶斯(naive_bayes.MultinomialNB)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E4%BC%AF%E5%8A%AA%E5%88%A9%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF-naive-bayes-BernoulliNB%EF%BC%89"><span class="toc-text">2.3 伯努利朴素贝叶斯(naive_bayes.BernoulliNB）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-TF-IDF"><span class="toc-text">3.TF-IDF</span></a></li></ol>
    </div>
  </div><div class="post-content"><p>朴素贝叶斯是基于贝叶斯决策理论和特征属性独立假设的生成方法。朴素贝叶斯中的朴素是指特征条件独立假设，贝叶斯定理是用来描述两个条件概率之间的关系。<a id="more"></a></p>
<h2 id="1-贝叶斯原理"><a href="#1-贝叶斯原理" class="headerlink" title="1.贝叶斯原理"></a>1.贝叶斯原理</h2><ul>
<li><strong>先验概率</strong>：通过经验来判断事情发生的概率，如全概率公式，它往往作为”由因求果”问题中的”因”出现的概率，比如南方的梅雨季是 6-7 月，就是通过往年的气候总结出来的经验，这个时候下雨的概率就比其他时间高出很多。</li>
<li><strong>后验概率</strong>：后验概率就是发生结果之后，推测原因的概率，是“执果寻因”问题中的”果”。先验概率与后验概率有不可分割的联系，后验概率的计算要以先验概率为基础，比如一本书现在已经被别人借走了（事件已经发生），已知只有可能是张三，李四，王五这3个人借走（事件发生的所有原因）。那么这本书被张三借走的概率会是多大呢？</li>
<li><strong>条件概率</strong>：事件 A 在另外一个事件 B 已经发生条件下的发生概率，表示为 P(A|B)，读作“在 B 发生的条件下 A 发生的概率”。比如原因 A 的条件下，发生B的概率，就是条件概率。</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2020/png/1045823/1601709391920-e2117d45-a868-4bba-8001-f440fa743141.png#align=left&display=inline&height=63&margin=%5Bobject%20Object%5D&name=image.png&originHeight=126&originWidth=532&size=15020&status=done&style=none&width=266" alt="image.png"></p>
<p>其中P(A)叫做先验概率，P(B|A)叫做条件概率，而我们所求的P(A|B)就叫做后验概率。</p>
<h2 id="2-sklearn中的朴素贝叶斯"><a href="#2-sklearn中的朴素贝叶斯" class="headerlink" title="2.sklearn中的朴素贝叶斯"></a>2.sklearn中的朴素贝叶斯</h2><p>三种算法适合应用在不同的场景下，我们应该根据特征变量的不同选择不同的算法：</p>
<h3 id="2-1-高斯朴素贝叶斯-naive-bayes-GaussianNB"><a href="#2-1-高斯朴素贝叶斯-naive-bayes-GaussianNB" class="headerlink" title="2.1 高斯朴素贝叶斯(naive_bayes.GaussianNB)"></a>2.1 高斯朴素贝叶斯(naive_bayes.GaussianNB)</h3><p>特征变量是连续变量，符合高斯分布，比如说人的身高，物体的长度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 导入模块</span></span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="comment"># 实例化</span></span><br><span class="line">gnb = GaussianNB()</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">gnb = gnb.fit(Xtrain,Ytrain)</span><br><span class="line"><span class="comment"># 查看分数</span></span><br><span class="line">acc_score = gnb.score(Xtest,Ytest) </span><br><span class="line"><span class="comment"># 查看预测结果</span></span><br><span class="line">Y_pred = gnb.predict(Xtest) </span><br><span class="line"><span class="comment"># 查看预测的结果</span></span><br><span class="line">prob = gnb.predict_proba(Xtest)</span><br></pre></td></tr></table></figure>
<h3 id="2-2-多项式朴素贝叶斯-naive-bayes-MultinomialNB"><a href="#2-2-多项式朴素贝叶斯-naive-bayes-MultinomialNB" class="headerlink" title="2.2 多项式朴素贝叶斯(naive_bayes.MultinomialNB)"></a>2.2 多项式朴素贝叶斯(naive_bayes.MultinomialNB)</h3><p>特征变量是离散变量，符合多项分布，在文档分类中特征变量体现在一个单词出现的次数，或者是单词的 TF-IDF 值等。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入模块</span></span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB </span><br><span class="line">mnb = MultinomialNB().fit(Xtrain,Ytrain)</span><br><span class="line"><span class="comment"># 获取每个标签类的先验概率</span></span><br><span class="line">mnb.class_log_prior_ </span><br><span class="line"><span class="comment"># 返回一个固定类别标签下每个特征的对数概率</span></span><br><span class="line">mnb.feature_log_prob_ </span><br></pre></td></tr></table></figure>
<h3 id="2-3-伯努利朴素贝叶斯-naive-bayes-BernoulliNB）"><a href="#2-3-伯努利朴素贝叶斯-naive-bayes-BernoulliNB）" class="headerlink" title="2.3 伯努利朴素贝叶斯(naive_bayes.BernoulliNB）"></a>2.3 伯努利朴素贝叶斯(naive_bayes.BernoulliNB）</h3><p>特征变量是布尔变量，符合 0/1 分布，在文档分类中特征是单词是否出现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> BernoulliNB</span><br><span class="line">mms = MinMaxScaler().fit(Xtrain)</span><br><span class="line">Xtrain_ = mms.transform(Xtrain)</span><br><span class="line">Xtest_ = mms.transform(Xtest)</span><br><span class="line">bnl_ = BernoulliNB().fit(Xtrain_, Ytrain)</span><br><span class="line">bnl_.score(Xtest_,Ytest)</span><br><span class="line">brier_score_loss(Ytest,bnl_.predict_proba(Xtest_)[:,<span class="number">1</span>],pos_label=<span class="number">1</span>) </span><br><span class="line">bnl = BernoulliNB(binarize=<span class="number">0.5</span>).fit(Xtrain_, Ytrain)</span><br><span class="line">bnl.score(Xtest_,Ytest)</span><br><span class="line">brier_score_loss(Ytest,bnl.predict_proba(Xtest_)[:,<span class="number">1</span>],pos_label=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="3-TF-IDF"><a href="#3-TF-IDF" class="headerlink" title="3.TF-IDF"></a>3.TF-IDF</h2><p>TF-IDF 是一个统计方法，用来评估某个词语对于一个文件集或文档库中的其中一份文件的重要程度。是由TF和IDF的乘积构成，分别代表了词频和逆向文档频率。这样我们倾向于找到 TF 和 IDF 取值都高的单词作为区分，即这个单词在一个文档中出现的次数多，同时又很少出现在其他文档中。这样的单词适合用于分类。<br><strong>词频 TF **：计算了一个单词在文档中出现的次数，它认为一个单词的重要性和它在文档中出现的次数呈正比。<br>**逆向文档频率 IDF：</strong>是指一个单词在文档中的区分度。它认为一个单词出现在的文档数越少，就越能通过这个单词把该文档和其他文档区分开。IDF 越大就代表该单词的区分度越大。<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1045823/1601726778842-4677606e-2d2c-45ec-93bd-2b3f9e1825c7.png#align=left&display=inline&height=222&margin=%5Bobject%20Object%5D&name=image.png&originHeight=444&originWidth=1100&size=162681&status=done&style=none&width=550" alt="image.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过feature_extraction.text模块中的TfidfVectorizer类查看每个词的权重，将原本出现比较多的词的词压缩，来压缩该词的权重，将原本出现比较次数少的词的词进行拓展，增加我们的权重</span></span><br><span class="line">sample = [<span class="string">&quot;Machine learning is fascinating, it is wonderful&quot;</span></span><br><span class="line">          ,<span class="string">&quot;Machine learning is a sensational techonology&quot;</span></span><br><span class="line">          ,<span class="string">&quot;Elsa is a popular character&quot;</span>]</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer <span class="keyword">as</span> TFIDF</span><br><span class="line">vec = TFIDF()</span><br><span class="line">X = vec.fit_transform(sample)</span><br><span class="line"></span><br><span class="line"><span class="comment">#每一个单词作为一个特征，每个单词在这个句子中所占的比列</span></span><br><span class="line"><span class="comment">#同样使用接口get_feature_names()调用每个列的名称</span></span><br><span class="line">TFIDFresult = pd.DataFrame(X.toarray(),columns=vec.get_feature_names())</span><br><span class="line">TFIDFresult.<span class="built_in">sum</span>(axis=<span class="number">0</span>) / TFIDFresult.<span class="built_in">sum</span>(axis=<span class="number">0</span>).<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>



      </div>
      
      <footer class="post-footer">
        <div class="post-tags">
            <a href="/tags/%E7%AE%97%E6%B3%95/">算法</a>
            </div>
        
        <nav class="post-nav"><a class="prev" href="/2019/10/05/%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E8%83%BD%E5%8A%9B%E5%BC%BA%E7%9A%84%E5%91%98%E5%B7%A5/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">如何管理能力强的员工</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    <a class="next" href="/2019/09/25/Anaconda%20for%20Mac%20%E5%AE%89%E8%A3%85%20Jupyter%20Nbextensions%20%E6%8F%92%E4%BB%B6%E9%97%AE%E9%A2%98/">
        <span class="next-text nav-default">Anaconda for Mac 安装 Jupyter Nbextensions 插件问题</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    </nav></footer>
    </article></div><div class="comments" id="comments">
      <div id="vcomments"></div>
    </div></div>
      </main>

      <footer id="footer" class="footer"><div class="social-links"><a href="mailto:huangdalu@yeah.net" class="iconfont icon-email" title="email"></a>
        <a target="_blank" rel="noopener" href="https://github.com/huang-dalu" class="iconfont icon-github" title="github"></a>
        <a target="_blank" rel="noopener" href="https://www.douban.com/people/108055759" class="iconfont icon-douban" title="douban"></a>
        <a href="/atom.xml" class="iconfont icon-rss" title="rss" target="_blank"></a>
    </div><div class="copyright"><span class="division">&nbsp;</span><span class="copyright-year">Since 2020 - 2021
      <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">huangdalu</span>
  </span>
</div>
</footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
<script src="./lib/valine/av-min.js?v=3.0.4"></script>
<script src='./lib/valine/Valine.min.js'></script>
<script type="text/javascript">
    new Valine({
        el: '#vcomments',
        notify: false,
        verify: false,
        app_id: "XtxvAXPwOzM9noIc3eyxi3AS-gzGzoHsz",
        app_key: "yEVQszyxb4bwLuAGU5VHnPR8",
        placeholder: "说点什么吧...",
        avatar: 'mm',
        visitor: 'ture'
    });
</script><script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  <script type="text/javascript" src="/js/src/even.js?v=2.11.0"></script>
</body>
</html>
